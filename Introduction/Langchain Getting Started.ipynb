{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv('../env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['LANGSMITH_ENDPOINT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of the Code\n",
    "\n",
    "1. **Importing the ChatOllama Class**\n",
    "   - The `ChatOllama` class is used to interact with the Ollama LLM (Large Language Model) API.\n",
    "\n",
    "2. **Defining the Base URL and Model**\n",
    "   - **`base_url`**: Specifies the URL where the Ollama server is running. In this case, it is hosted locally on port `11434`.\n",
    "   - **`model`**: Defines the specific LLM model to use. Here, the model is `llama3.2:1b`.\n",
    "\n",
    "3. **Creating an Instance of ChatOllama**\n",
    "   - An instance of the `ChatOllama` class is created with the following parameters:\n",
    "     - **`base_url`**: The URL of the Ollama server.\n",
    "     - **`model`**: The LLM model to use.\n",
    "     - **`temperature`**: Controls the randomness of the model's output. A value of `0.8` allows for some creativity while maintaining coherence.\n",
    "     - **`num_predict`**: Specifies the maximum number of tokens to predict in the response.\n",
    "\n",
    "4. **Invoking the Model with a Prompt**\n",
    "   - The `invoke` method sends a prompt to the LLM and retrieves the response.\n",
    "   - The prompt in this case is: *\"Please explain langchain using 5 simple usecases.\"*\n",
    "\n",
    "5. **Printing the Response**\n",
    "   - The `print` function is used to display the content of the response received from the LLM.\n",
    "   - The `response.content` contains the text generated by the model based on the provided prompt.\n",
    "\n",
    "### Summary\n",
    "- This code demonstrates how to use the `ChatOllama` class to interact with an Ollama LLM.\n",
    "- It initializes the model with specific parameters, sends a prompt, and prints the generated response.\n",
    "- This is useful for generating natural language explanations or other text-based outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a web-based conversational AI platform that enables users to engage in natural language conversations with chatbots, allowing for more human-like interactions and improving the efficiency of various processes. Here are five detailed and distinct use cases for LangChain:\n",
      "\n",
      "**Use Case 1: Customer Support Chatbots**\n",
      "\n",
      "In this scenario, customers interact with LangChain's chatbot, which is designed to provide assistance and resolve issues related to a company's products or services. The chatbot can ask questions, gather information, and offer solutions to help customers troubleshoot problems or find answers to their queries. By leveraging LangChain's conversational AI capabilities, companies can reduce the workload of human customer support agents, improve response times, and provide better customer experience.\n",
      "\n",
      "For example, a customer service representative might use LangChain to ask questions about product features, order status, or return policies. The chatbot would respond with relevant information, such as troubleshooting steps or recommended solutions. If the customer needs additional assistance, the chatbot can escalate the issue to a human agent for further support.\n",
      "\n",
      "**Use Case 2: Business Process Automation**\n",
      "\n",
      "In this use case, LangChain is used to automate business processes by integrating it with other applications and systems. For instance, companies might use LangChain to automate routine tasks such as data entry, document processing, or payment processing. By connecting LangChain to various workflow automation tools, businesses can streamline their operations, reduce manual errors, and improve efficiency.\n",
      "\n",
      "For example, a company might use LangChain to automate the process of extracting customer information from customer databases, then using that information to personalize marketing messages or offers. This would enable businesses to deliver targeted promotions and improve customer engagement without relying on human intervention.\n",
      "\n",
      "**Use Case 3: Language Translation and Interpretation**\n",
      "\n",
      "In this scenario, LangChain is used for language translation and interpretation services, enabling users to communicate effectively across linguistic and cultural boundaries. By leveraging LangChain's conversational AI capabilities, individuals can engage in real-time conversations with people from different countries or cultures, facilitating international business transactions, education, and tourism.\n",
      "\n",
      "For instance, a traveler might use LangChain to ask questions about local customs, transportation, or accommodation options while traveling abroad. The chatbot would respond with relevant information, such as translation of important phrases, cultural insights, or travel advisories. This would help travelers navigate unfamiliar environments more efficiently and safely.\n",
      "\n",
      "**Use Case 4: Knowledge Graph-based Search**\n",
      "\n",
      "In this use case, LangChain is used to create a knowledge graph-based search system that enables users to find specific information by\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model=model,\n",
    "    temperature=0.5,\n",
    "    num_predict=512\n",
    "    #timeout=None,\n",
    "    # max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "   \n",
    ")\n",
    "\n",
    "# 'Please explain {topic} using exactly {number} detailed and distinct use cases.'\n",
    "response = llm.invoke('Please explain langchain using exactly 5 detailed and distinct use cases.')\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = \"\"\n",
    "# for chunk in llm.stream('Please explain langchain using 5 usecases'):\n",
    "#     response = response + \" \" + chunk.content\n",
    "#     print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2:1b',\n",
       " 'created_at': '2025-03-26T12:02:04.916020597Z',\n",
       " 'done': True,\n",
       " 'done_reason': 'length',\n",
       " 'total_duration': 28643916289,\n",
       " 'load_duration': 3975598061,\n",
       " 'prompt_eval_count': 35,\n",
       " 'prompt_eval_duration': 1067784576,\n",
       " 'eval_count': 256,\n",
       " 'eval_duration': 23599163456,\n",
       " 'message': Message(role='assistant', content='', images=None, tool_calls=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Prompt Template\n",
    "## What is a PromptTemplate?\n",
    "The PromptTemplate is a utility class used to create dynamic and reusable prompts for language models. It allows you to define a template with placeholders and then populate those placeholders with specific values at runtime.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a web-based, open-source conversational AI platform that enables developers to build conversational interfaces using natural language processing (NLP) and machine learning (ML). Here are five detailed and distinct use cases for LangChain:\n",
      "\n",
      "**Use Case 1: Chatbots for Customer Support**\n",
      "\n",
      "LangChain can be used to build custom chatbots for customer support, allowing businesses to provide 24/7 assistance to their customers. With LangChain, developers can create conversational interfaces that can understand natural language queries, respond with relevant information, and even escalate complex issues to human representatives.\n",
      "\n",
      "For example, a company like Amazon uses LangChain to power its chatbot, Alexa, which provides personalized product recommendations, answers customer questions, and helps with shopping tasks. By integrating LangChain into their platform, businesses can offer similar conversational experiences to their customers.\n",
      "\n",
      "**Use Case 2: Virtual Assistants for Productivity**\n",
      "\n",
      "LangChain can be used to build virtual assistants that help users manage their time, organization, and productivity. These virtual assistants can understand natural language inputs, provide recommendations, and even schedule appointments or reminders.\n",
      "\n",
      "For instance, a student might use LangChain as a virtual assistant to stay organized with their coursework, set reminders for upcoming exams, and receive personalized study tips. By integrating LangChain into their workflow, students can streamline their productivity and reduce stress.\n",
      "\n",
      "**Use Case 3: Voice-Based Interfaces for IoT Devices**\n",
      "\n",
      "LangChain can be used to power voice-based interfaces for IoT devices, such as smart home appliances or security systems. These devices can understand natural language inputs from users, respond with relevant actions, and even integrate with other devices in the network.\n",
      "\n",
      "For example, a smart thermostat might use LangChain to control its temperature based on user input, while a security camera might use it to alert users of motion detection or suspicious activity. By integrating LangChain into their devices, manufacturers can create more intuitive and user-friendly interfaces for their products.\n",
      "\n",
      "**Use Case 4: Conversational Interfaces for Healthcare**\n",
      "\n",
      "LangChain can be used to build conversational interfaces that help patients manage their health and wellness. These interfaces can understand natural language inputs from users, provide personalized recommendations, and even connect them with healthcare professionals.\n",
      "\n",
      "For instance, a patient might use LangChain to ask questions about their condition, receive medication instructions, or schedule follow-up appointments with their doctor. By integrating LangChain into their care plan, patients can better manage their health and reduce healthcare costs.\n",
      "\n",
      "**Use Case 5: Language Translation and Interpretation**\n",
      "\n",
      "LangChain can be used to power language\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the base URL and model\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "\n",
    "# Create an instance of ChatOllama\n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model=model,\n",
    "    temperature=0.5,\n",
    "    num_predict=512\n",
    ")\n",
    "\n",
    "# Create a PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"number\"],\n",
    "    template=\"Please explain {topic} using exactly {number} detailed and distinct use cases.\"\n",
    ")\n",
    "\n",
    "# Format the prompt with dynamic values\n",
    "formatted_prompt = prompt_template.format(topic=\"langchain\", number=5)\n",
    "\n",
    "# Invoke the model with the formatted prompt\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LCEL\n",
    "LCEL (LangChain Expression Language) is a declarative way to compose chains in LangChain that allows you to describe what should happen, rather than how it should happen.\n",
    "\n",
    "``` python\n",
    "# Old approach (imperative)\n",
    "formatted_prompt = prompt_template.format(topic=\"langchain\", number=5)\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# LCEL approach (declarative)\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"langchain\", \"number\": 5})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a decentralized, open-source, and multi-chain protocol that enables the creation of a chainless blockchain by aggregating multiple chains into one. Here are five detailed and distinct use cases for LangChain:\n",
      "\n",
      "**Use Case 1: Decentralized Finance (DeFi) Applications**\n",
      "\n",
      "LangChain can be used to build DeFi applications that leverage the strengths of different blockchain networks. For example, a decentralized lending protocol can be built on top of multiple chains, such as Ethereum, Binance Smart Chain, and Polygon, allowing users to lend and borrow assets across different networks with minimal latency and high scalability.\n",
      "\n",
      "The use case involves creating a decentralized lending platform that allows users to lend or borrow assets from various DeFi protocols. The platform would need to integrate with multiple chains, each supporting different smart contract languages (e.g., Ethereum, BSC, Polygon). This would enable the creation of a seamless user experience across multiple networks, reducing costs and increasing adoption.\n",
      "\n",
      "**Use Case 2: Cross-Chain Bridge for Interoperability**\n",
      "\n",
      "LangChain can be used as a cross-chain bridge to enable seamless interactions between different blockchain networks. For instance, a decentralized application (dApp) built on Ethereum can interact with a dApp built on Binance Smart Chain without needing to switch between chains.\n",
      "\n",
      "The use case involves creating a bridge protocol that enables the transfer of assets and data between different chains. This would require the development of a cross-chain bridge that can handle high volumes of transactions, ensure secure and reliable interactions, and comply with regulatory requirements.\n",
      "\n",
      "**Use Case 3: Smart Contract Orchestration for Complex Applications**\n",
      "\n",
      "LangChain can be used to orchestrate complex smart contracts across multiple chains. For example, a decentralized autonomous organization (DAO) built on Ethereum can use LangChain to deploy and manage its governance protocol on other chains, such as Binance Smart Chain or Polygon.\n",
      "\n",
      "The use case involves creating a smart contract orchestration platform that enables the deployment of complex applications across multiple chains. This would require the development of a framework that can handle the complexities of multi-chain deployment, including security, scalability, and interoperability.\n",
      "\n",
      "**Use Case 4: Multi-Chain Data Storage for Decentralized Applications**\n",
      "\n",
      "LangChain can be used to build decentralized applications (dApps) that require large amounts of data storage across multiple chains. For example, a dApp built on Ethereum can use LangChain to store and manage its own data in a decentralized manner.\n",
      "\n",
      "The use case involves creating a multi-chain data storage solution that enables the efficient management of large datasets across different blockchain\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# Define the base URL and model\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "\n",
    "# Create an instance of ChatOllama\n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model=model,\n",
    "    temperature=0.5,\n",
    "    num_predict=512\n",
    ")\n",
    "\n",
    "# Create a PromptTemplate using LCEL\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Please explain {topic} using exactly {number} detailed and distinct use cases.\"\n",
    ")\n",
    "\n",
    "# Compose the chain using LCEL pipe operator\n",
    "chain = (\n",
    "    prompt \n",
    "    | llm\n",
    ")\n",
    "\n",
    "# Invoke the chain with input values\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"langchain\", \n",
    "    \"number\": 5\n",
    "})\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
