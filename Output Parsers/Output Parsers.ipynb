{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709ca7be",
   "metadata": {},
   "source": [
    "# Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6caf2db-0362-41d4-8e63-871d9112e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "# Initialize the Llama model \n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model = model,\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9093729e",
   "metadata": {},
   "source": [
    "# Chain Processing without / with the output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27680941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Without Parser ---\n",
      "Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Content: As I'm a large language model, I don't have real-time access to current weather conditions. However, I can suggest some ways for you to find out the current weather in San Francisco.\n",
      "\n",
      "You can check the weather forecast for San Francisco by visiting a weather website or app, such as:\n",
      "\n",
      "* National Weather Service (weather.gov)\n",
      "* AccuWeather (accuweather.com)\n",
      "* Weather Underground (wunderground.com)\n",
      "\n",
      "These websites will provide you with the current weather conditions, including temperature, humidity, wind speed, and precipitation forecasts, for San Francisco.\n",
      "\n",
      "If you're looking for a specific date or period of time, I can try to help you find a reliable source of information.\n",
      "\n",
      "--- With StrOutputParser ---\n",
      "Type: <class 'str'>\n",
      "Content: In my knowledge cutoff of March 2023, I can provide you with general information about the typical weather patterns in San Francisco. However, please note that this information might not be up-to-date or specific to your current location.\n",
      "\n",
      "San Francisco is known for its mild climate, with temperatures ranging from the mid-40s to mid-70s Fahrenheit (7-23°C) throughout the year. The city experiences a Mediterranean climate, characterized by:\n",
      "\n",
      "* Mild winters: San Francisco's average temperature in January, the coldest month, is around 47°F (8°C), while the average high temperature is 59°F (15°C).\n",
      "* Cool summers: The average temperature in July, the warmest month, is around 73°F (23°C), while the average high temperature is 75°F (24°C).\n",
      "* Wet winters and dry summers: San Francisco can experience significant rainfall during its winter months due to its proximity to the Pacific Ocean. On the other hand, summers are usually dry, with an average of only 2 inches (50 mm) of precipitation.\n",
      "* Spring and fall seasons: These periods typically see mild temperatures, making them pleasant for outdoor activities.\n",
      "\n",
      "Keep in mind that these are general trends, and local conditions can vary depending on the specific location\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Without parser\n",
    "print(\"--- Without Parser ---\")\n",
    "response = llm.invoke(\"What's the weather in San Francisco?\")\n",
    "print(\"Type:\", type(response))\n",
    "print(\"Content:\", response.content)\n",
    "\n",
    "\n",
    "# With StrOutputParser\n",
    "print(\"\\n--- With StrOutputParser ---\")\n",
    "chain = llm | StrOutputParser()\n",
    "response = chain.invoke(\"What's the weather in San Francisco?\")\n",
    "print(\"Type:\", type(response))\n",
    "print(\"Content:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790c192a",
   "metadata": {},
   "source": [
    "# StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5242f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stripe Overview:\n",
      "{'company_name': 'Stripe', 'supported_countries': 'Global (over 180 countries)', 'supported_card_types': 'Visa, Mastercard, Amex, Discover, JCB', 'key_features': 'Real-time transactions, secure and scalable payment processing, PCI-DSS compliant, multi-currency support, real-time API for custom integrations', 'transaction_fees': 'Competitive pricing model, transaction fees range from $0.000004 to $3.99 per transaction, no monthly or yearly subscription fees'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define response schemas for payment processing information\n",
    "response_schemas = [\n",
    "    ResponseSchema(\n",
    "        name=\"company_name\", \n",
    "        description=\"Name of the payment processing company\"\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"supported_countries\", \n",
    "        description=\"List of countries where the payment processor operates\"\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"supported_card_types\", \n",
    "        description=\"Types of credit/debit cards supported\"\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"key_features\", \n",
    "        description=\"Key features and unique selling points of the payment processor\"\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"transaction_fees\", \n",
    "        description=\"Overview of transaction fees or pricing model\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create a structured output parser\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Get format instructions for the output\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Create a prompt template specific to payment processing companies\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an expert in payment processing technologies. \n",
    "Provide a comprehensive overview of the payment processing company based on the query.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Query: {question}\n",
    "\n",
    "Provide detailed, accurate information about the payment processor, focusing on its capabilities, market presence, and unique characteristics.\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# Initialize the ChatOpenAI model\n",
    "# model = ChatOpenAI(temperature=0.3, model=\"gpt-4-turbo\")\n",
    "\n",
    "# Create the processing chain\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# Example queries about payment processors\n",
    "print(\"Stripe Overview:\")\n",
    "stripe_info = chain.invoke({\"question\": \"Provide details about Stripe payment processing\"})\n",
    "print(stripe_info)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd103f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stripe Overview:\n",
      "An error occurred: Failed to parse PaymentProcessorInfo from completion {\"company_name\": \"Stripe\", \"description\": \"A financial services company that provides online payment processing solutions.\", \"supported_countries\": [\"AF\", \"AX\", \"AW\", \"AD\", \"AE\", \"AL\", \"AM\", \"AO\", \"AZ\", \"BA\", \"BH\", \"BD\", \"BB\", \"BY\", \"BZ\", \"BM\", \"BF\", \"BG\", \"BI\", \"KH\", \"CM\", \"CV\", \"CI\", \"CF\", \"CG\", \"CD\", \"CN\", \"CK\", \"CX\", \"CY\", \"CZ\", \"DE\", \"DJ\", \"DK\", \"DM\", \"DO\", \"DZ\", \"EC\", \"EG\", \"SV\", \"GQ\", \"ER\", \"EE\", \"ET\", \"FI\", \"FJ\", \"FR\", \"GF\", \"PF\", \"VG\", \"GU\"]}. Got: 3 validation errors for PaymentProcessorInfo\n",
      "supported_card_types\n",
      "  Field required [type=missing, input_value={'company_name': 'Stripe'...'GF', 'PF', 'VG', 'GU']}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "key_features\n",
      "  Field required [type=missing, input_value={'company_name': 'Stripe'...'GF', 'PF', 'VG', 'GU']}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "transaction_fees\n",
      "  Field required [type=missing, input_value={'company_name': 'Stripe'...'GF', 'PF', 'VG', 'GU']}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:3b'\n",
    "# Initialize the Llama model \n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model = model,\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256\n",
    ")\n",
    "# Pydantic\n",
    "from typing import List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define a Pydantic model for payment processing information\n",
    "class PaymentProcessorInfo(BaseModel):\n",
    "    company_name: str = Field(description=\"Name of the payment processing company\")\n",
    "    supported_countries: List[str] = Field(description=\"List of countries where the payment processor operates\")\n",
    "    supported_card_types: List[str] = Field(description=\"Types of credit/debit cards supported\")\n",
    "    key_features: List[str] = Field(description=\"Key features and unique selling points of the payment processor\")\n",
    "    transaction_fees: str = Field(description=\"Overview of transaction fees or pricing model\")\n",
    "\n",
    "# Create a Pydantic output parser\n",
    "output_parser = PydanticOutputParser(pydantic_object=PaymentProcessorInfo)\n",
    "\n",
    "# Create a prompt template specific to payment processing companies\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an expert in payment processing technologies. \n",
    "Provide a comprehensive overview of the payment processing company based on the query.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Query: {question}\n",
    "\n",
    "Provide  detailed, accurate information about the payment processor,that complies with the schema,  focusing on its capabilities, market presence, and unique characteristics.\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "#  # Initialize the ChatOpenAI model\n",
    "# model = ChatOpenAI(temperature=0.3) \n",
    "\n",
    "# Create the processing chain\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# Example queries about payment processors\n",
    "try:\n",
    "    print(\"Stripe Overview:\")\n",
    "    stripe_info = chain.invoke({\"question\": \"Provide details about Stripe payment processing\"})\n",
    "    print(stripe_info)\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
