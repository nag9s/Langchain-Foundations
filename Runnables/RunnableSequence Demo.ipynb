{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87613666",
   "metadata": {},
   "source": [
    "### Runnable Sequences and Activities in This Notebook\n",
    "\n",
    "**Runnable Sequences**  \n",
    "- A `RunnableSequence` is a pipeline that chains multiple operations, where the output of one step becomes the input for the next.  \n",
    "- It is used to create workflows for tasks like text analysis, generation, or transformation.\n",
    "\n",
    "**Activities in This Notebook**  \n",
    "- **Model Initialization**: `ChatOllama` model is initialized with parameters like base URL, model name, and temperature.  \n",
    "- **Prompt Template Creation**: A `ChatPromptTemplate` is defined for analyzing payment transaction details.  \n",
    "- **Runnable Sequence Definition**: A sequence is created to format the prompt, process it with the model, and parse the output.  \n",
    "- **Transaction Analysis**: A function is implemented to analyze transactions and print risk assessments and fraud indicators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e716a34-ed5b-4476-ab8c-2c3a6660a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv('../env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6caf2db-0362-41d4-8e63-871d9112e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "# Initialize the Llama model \n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model = model,\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6649b76-ce6c-4b44-8599-0887ed01921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "\n",
    "\n",
    "# Create a prompt template for financial transaction analysis\n",
    "transaction_analysis_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Analyze the following payment transaction details:\n",
    "    - Transaction Amount: {amount}\n",
    "    - Merchant: {merchant}\n",
    "    - Transaction Type: {transaction_type}\n",
    "\n",
    "    Provide a detailed risk assessment and potential fraud indicators.\"\"\"\n",
    ")\n",
    "\n",
    "# Create a RunnableSequence to process the transaction\n",
    "transaction_analysis_chain = (\n",
    "    transaction_analysis_prompt  # First, format the prompt\n",
    "    | llm  # Then, pass to the Llama model for analysis\n",
    "    | StrOutputParser()  # Convert the model output to a string\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "def analyze_transaction(amount, merchant, transaction_type):\n",
    "    result = transaction_analysis_chain.invoke({\n",
    "        \"amount\": amount,\n",
    "        \"merchant\": merchant,\n",
    "        \"transaction_type\": transaction_type\n",
    "    })\n",
    "    return result\n",
    "\n",
    "# Demonstrate the chain\n",
    "transaction_result = analyze_transaction(\n",
    "    amount=\"$1,250.75\", \n",
    "    merchant=\"TechCorp Online Store\", \n",
    "    transaction_type=\"E-commerce Purchase\"\n",
    ")\n",
    "\n",
    "print(\"Transaction Analysis:\")\n",
    "print(transaction_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
