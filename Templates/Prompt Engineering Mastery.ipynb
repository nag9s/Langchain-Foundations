{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Prompt Templates : Mastering Prompt Engineering in LangChain\n",
    "\n",
    "## Overview\n",
    "ChatPromptTemplate is a powerful tool in LangChain that allows you to define structured prompts for conversational AI models. It enables you to create prompts with multiple message types and provides flexibility for complex conversational scenarios.\n",
    "\n",
    "\n",
    "## Key Features:\n",
    "- Supports multiple message types (system, human, AI)\n",
    "- Can include context and role-specific instructions\n",
    "- More flexible for complex conversational scenarios\n",
    "- Outputs a list of messages\n",
    "- Better suited for chat models that expect a sequence of messages\n",
    "\n",
    "\n",
    "\n",
    "## Technologies Used:\n",
    "- LangChain\n",
    "- Ollama LLM\n",
    "- ChatPromptTemplate\n",
    "- PromptTemplate\n",
    "- Message-based Communication\n",
    "- LCEL (LangChain Expression Language)\n",
    "\n",
    "## Use Cases:\n",
    "- Conversational AI development\n",
    "- Intelligent chatbot design\n",
    "- Dynamic content generation\n",
    "- Context-aware communication systems\n",
    "- Advanced prompt engineering\n",
    "\n",
    "## Comparative Prompt Template Approaches\n",
    "\n",
    "| Aspect               | PromptTemplate                          | ChatPromptTemplate                          |\n",
    "|-----------------------|-----------------------------------------|---------------------------------------------|\n",
    "| **Message Structure** | Single string                          | Multiple message types (system, human, AI) |\n",
    "| **Use Cases**         | Simple, single-turn interactions       | Multi-turn conversations, context-rich interactions |\n",
    "| **Model Compatibility** | Works with traditional language models | Designed for chat-based models             |\n",
    "\n",
    "## Learning Objectives:\n",
    "- Understand prompt template fundamentals\n",
    "- Create dynamic, context-aware prompts\n",
    "- Implement multi-turn conversation strategies\n",
    "- Master message-based communication\n",
    "- Design intelligent conversational interfaces\n",
    "\n",
    "## Key Challenges Addressed:\n",
    "- Prompt variability\n",
    "- Contextual communication\n",
    "- Model-specific prompt requirements\n",
    "\n",
    "#### When to Use Each\n",
    "\n",
    "**Use `PromptTemplate` for:**\n",
    "- Simple, single-turn queries\n",
    "- Traditional language models\n",
    "- Straightforward text generation\n",
    "\n",
    "**Use `ChatPromptTemplate` for:**\n",
    "- Conversational AI\n",
    "- Multi-turn interactions\n",
    "- Scenarios requiring context or role-based instructions\n",
    "- Chat models like GPT-3.5, GPT-4\n",
    "\n",
    "The choice depends on your specific use case and the type of language model you're using.\n",
    "\n",
    "\n",
    "\n",
    "## Reference\n",
    "For more details, please visit [Prompt Templates Documentation](https://python.langchain.com/docs/concepts/prompt_templates/) and [Chat Models Documentation](https://python.langchain.com/docs/concepts/chat_models/).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model=model,\n",
    "    temperature=0.5,\n",
    "    num_predict=512\n",
    "    #timeout=None,\n",
    "    # max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Messages in Chat Models\n",
    "\n",
    "Messages are the fundamental units of communication in chat models, representing inputs, outputs, and any associated context or metadata. Each message includes:\n",
    "\n",
    "- **Role**: Defines the message's origin (e.g., \"user\", \"assistant\").\n",
    "- **Content**: Contains the message data (e.g., text, multimodal data).\n",
    "- **Metadata**: Additional information that varies by chat model provider.\n",
    "\n",
    "LangChain offers a unified message format, enabling seamless interaction with various chat models without concern for provider-specific message formats. \n",
    "| **Role**          | **Description**                                                                                                                                   |\n",
    "|--------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **system**         | Used to tell the chat model how to behave and provide additional context. Not supported by all chat model providers.                              |\n",
    "| **user**           | Represents input from a user interacting with the model, usually in the form of text or other interactive input.                                 |\n",
    "| **assistant**      | Represents a response from the model, which can include text or a request to invoke tools.                                                       |\n",
    "| **tool**           | A message used to pass the results of a tool invocation back to the model after external data or processing has been retrieved.                  |\n",
    "| **function (legacy)** | This is a legacy role, corresponding to OpenAI's legacy function-calling API. `tool` role should be used instead.                              |\n",
    "\n",
    "For more details, please visit [LangChain Messages Documentation](https://python.langchain.com/docs/concepts/messages).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['number', 'topic'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assistant specialized in explaining technical concepts.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['number', 'topic'], input_types={}, partial_variables={}, template='Please explain {topic} using exactly {number} detailed and distinct use cases.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a ChatPromptTemplate with multiple message types\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant specialized in explaining technical concepts.\"),\n",
    "    (\"human\", \"Please explain {topic} using exactly {number} detailed and distinct use cases.\")\n",
    "])\n",
    "\n",
    "# Invoke the chat prompt with specific values\n",
    "formatted_chat_prompt = chat_prompt.invoke({\n",
    "    \"topic\": \"langchain\", \n",
    "    \"number\": 2\n",
    "})\n",
    "chat_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI assistant specialized in explaining technical concepts.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Please explain langchain using exactly 2 detailed and distinct use cases.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source, graph-based neural network architecture specifically designed for natural language processing (NLP) tasks such as text generation and translation. It was introduced by the AI research organization LangChain Labs in 2020.\n",
      "\n",
      "Here are two detailed and distinct use cases that highlight the capabilities of LangChain:\n",
      "\n",
      "**Use Case 1: Text Generation**\n",
      "\n",
      "LangChain can be used to generate human-like text based on a given prompt or input sequence. This is particularly useful for applications such as chatbots, language translation systems, and content generation tools.\n",
      "\n",
      "For example, imagine you want to create a conversational AI that can engage in a conversation with a user. You provide the LangChain model with a prompt like \"Write a short story about a character who discovers a hidden world\" or \"Generate a dialogue between two friends discussing their plans for the weekend\". The model then generates a text response, which can be used as input to train more conversational AI models.\n",
      "\n",
      "LangChain's graph-based architecture allows it to capture complex relationships between words and phrases, enabling it to generate coherent and engaging text. Additionally, LangChain can be fine-tuned on specific domains or tasks, making it an effective tool for generating high-quality text.\n",
      "\n",
      "**Use Case 2: Text Translation**\n",
      "\n",
      "LangChain can also be used for text translation, allowing users to translate text from one language to another in real-time. This is particularly useful for applications such as language learning platforms, online collaboration tools, and travel guides.\n",
      "\n",
      "For example, imagine you want to create a travel guide that provides translations of text content, such as hotel descriptions, restaurant menus, or tourist information. You can use LangChain's model to generate these translations in real-time, allowing users to access the translated content without needing to manually translate it.\n",
      "\n",
      "LangChain's graph-based architecture enables it to capture complex linguistic patterns and relationships between words, making it an effective tool for text translation. Additionally, LangChain can be fine-tuned on specific domains or tasks, such as translating technical documents or literary works, making it a powerful tool for language professionals.\n",
      "\n",
      "In both use cases, LangChain's graph-based architecture enables it to capture complex linguistic patterns and relationships between words, making it an effective tool for natural language processing tasks.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the model with the formatted prompt\n",
    "response = llm.invoke(formatted_chat_prompt)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI assistant who explains technical concepts in a friendly, approachable manner.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you help me understand what langchain is?', additional_kwargs={}, response_metadata={}), AIMessage(content='langchain is a powerful framework for developing applications powered by large language models. It provides tools to help chain together different components of AI applications.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Please explain langchain using exactly 5 detailed and distinct use cases.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same example as above but with conversational context\n",
    "\n",
    "# Create a ChatPromptTemplate that simulates a more interactive conversation\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # Role , Message\n",
    "    # System message sets the overall context and behavior\n",
    "    # SystemMessage(content=\"You are a helpful AI assistant who explains technical concepts in a friendly, approachable manner.\"),\n",
    "    (\"system\", \"You are a helpful AI assistant who explains technical concepts in a friendly, approachable manner.\"),\n",
    "    \n",
    "    # First human message sets up the initial context\n",
    "    # HumanMessage(content=\"Can you help me understand what {topic} is?\"),\n",
    "    (\"human\", \"Can you help me understand what {topic} is?\"),\n",
    "    \n",
    "    # An example AI response (this helps provide context for the model)\n",
    "    # AiMessage(content=\"{topic} is a powerful framework for developing applications powered by large language models. It provides tools to help chain together different components of AI applications.\"),\n",
    "    (\"ai\", \"{topic} is a powerful framework for developing applications powered by large language models. It provides tools to help chain together different components of AI applications.\"),\n",
    "    \n",
    "    # Another human follow-up message\n",
    "    # HumanMessage(content=\"Please explain {topic} using exactly {number} detailed and distinct use cases.\")\n",
    "    (\"human\", \"Please explain {topic} using exactly {number} detailed and distinct use cases.\")\n",
    "])\n",
    "\n",
    "# Invoke the prompt with specific values\n",
    "formatted_chat_prompt = chat_prompt.invoke({\n",
    "    \"number\": 5,\n",
    "    \"topic\": \"langchain\"\n",
    "})\n",
    "\n",
    "formatted_chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are five detailed and distinct use cases for langchain:\\n\\n**Use Case 1: Conversational AI**\\n\\nLangchain can be used to build conversational interfaces that integrate multiple models, such as intent detection, entity extraction, and response generation. For example, a customer service chatbot can use langchain to analyze user input, identify the intent behind their query (e.g., \"I want to know about our product\"), and then generate a relevant response from one of its models.\\n\\n* Integrate multiple models (e.g., NLP, sentiment analysis, language understanding) into a single conversational interface.\\n* Use langchain\\'s built-in support for chaining models to create complex conversations that involve multiple steps and transformations.\\n\\n**Use Case 2: Content Generation**\\n\\nLangchain can be used to generate high-quality content, such as articles, blog posts, or social media posts. For example, a news outlet can use langchain to analyze a given topic, identify relevant entities, and then generate a draft article using one of its models.\\n\\n* Integrate multiple NLP models (e.g., text summarization, entity extraction) into a single content generation pipeline.\\n* Use langchain\\'s built-in support for chaining models to create complex content that incorporates multiple sources and perspectives.\\n\\n**Use Case 3: Question Answering**\\n\\nLangchain can be used to build question answering systems that integrate multiple knowledge graphs and models. For example, an e-commerce platform can use langchain to analyze a user\\'s query (e.g., \"What is the price of the iPhone 13?\"), identify relevant entities in its knowledge graph, and then generate a list of potential answers from one of its models.\\n\\n* Integrate multiple knowledge graphs (e.g., product information, customer reviews) into a single question answering system.\\n* Use langchain\\'s built-in support for chaining models to create complex queries that involve multiple steps and transformations.\\n\\n**Use Case 4: Sentiment Analysis**\\n\\nLangchain can be used to build sentiment analysis systems that integrate multiple NLP models (e.g., text classification, sentiment analysis). For example, a social media analytics platform can use langchain to analyze user feedback (e.g., \"I love this product!\"), identify relevant entities in its knowledge graph, and then generate a sentiment score using one of its models.\\n\\n* Integrate multiple NLP models into a single sentiment analysis pipeline.\\n* Use langchain\\'s built-in support for chaining models to create complex sentiment analysis tasks that involve multiple steps and transformations.\\n\\n**Use Case 5: Text Sum'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(formatted_chat_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'d be happy to explain langchain with two detailed and distinct use cases.\\n\\n**Use Case 1: Chatbot Development**\\n\\nLangchain is particularly useful for building chatbots, which can engage in natural-sounding conversations with users. Here\\'s how:\\n\\nImagine you want to create a chatbot that helps customers find information about your products or services. You could use langchain to build the following components:\\n\\n* **Model**: Train a large language model (LLM) like BERT or RoBERTa on a dataset of customer support queries and responses. This will allow the chatbot to understand the context and intent behind the user\\'s query.\\n* **Transformer**: Use the transformer architecture provided by langchain to process the input text from the LLM. The transformer will break down the input into smaller chunks, or \"tokens,\" that can be fed into the model for processing.\\n* **Dialog Management**: Create a dialog management system using langchain\\'s `dialog` module to manage the conversation flow between the user and the chatbot. This includes determining when to respond with an LLM prompt, handling user input, and updating the state of the conversation.\\n* **Post-processing**: Use langchain\\'s `postprocess` module to refine the output from the LLM, such as by adding context or clarifying any ambiguities.\\n\\nBy chaining these components together using langchain, you can create a chatbot that is responsive, informative, and engaging. For example:\\n\\n1. A user asks the chatbot \"What are the benefits of our new product?\"\\n2. The LLM processes the input text and generates an LLM prompt: \"How do our new product benefit customers?\"\\n3. The transformer breaks down the input into tokens and feeds them into the model for processing.\\n4. The model responds with a summary of the benefits, which is then sent back to the chatbot as output.\\n\\n**Use Case 2: Content Generation**\\n\\nLangchain can also be used to generate high-quality content, such as articles, product descriptions, or even entire websites. Here\\'s how:\\n\\nImagine you want to create an article about a new feature in your software. You could use langchain to build the following components:\\n\\n* **Model**: Train a large language model (LLM) on a dataset of existing articles and website content. This will allow the chatbot to understand the structure, tone, and style of different types of content.\\n* **Content Generation**: Use the transformer architecture provided by langchain to generate new text based on the input from the LLM.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, you can use the `invoke` method directly on the ChatPromptTemplate using LCEL\n",
    "chain = chat_prompt | llm\n",
    "chain.invoke({ \"number\": 2,\n",
    "    \"topic\": \"langchain\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates\n",
    "Prompt Templates are a powerful way to define reusable and parameterized prompts for language models. They allow you to create dynamic prompts by using placeholders that can be replaced with specific values at runtime. This approach simplifies the process of generating customized prompts for various use cases.\n",
    "\n",
    "In contrast, Langchain Chat Prompt Templates are specifically designed for multi-turn conversations. They allow you to define structured prompts that include both system and user messages, making them ideal for chat-based interactions. While Prompt Templates focus on single-turn prompts with placeholders, Chat Prompt Templates provide additional flexibility for managing conversational context.\n",
    "\n",
    "Below, we discuss two methods to work with Prompt Templates:\n",
    "1. Using the `from_template()` method for quick and convenient creation of templates.\n",
    "2. Creating a `PromptTemplate` object explicitly with input variables for more customization.\n",
    "\n",
    "Key Characteristics of PromptTemplate\n",
    "- Works with a single string template  \n",
    "- Uses simple `{variable}` placeholders  \n",
    "- Best for straightforward, single-message prompts  \n",
    "- Outputs a single formatted string  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model=model,\n",
    "    temperature=0.5,\n",
    "    num_predict=512\n",
    "    #timeout=None,\n",
    "    # max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "   \n",
    ")\n",
    "\n",
    "# 'Please explain {topic} using exactly {number} detailed and distinct use cases.'\n",
    "# response = llm.invoke('Please explain langchain using exactly 2 detailed and distinct use cases.')\n",
    "\n",
    "#print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 : Using the from_template() method\n",
    "The `from_template()` method is used to create a `PromptTemplate` object by providing a template string with placeholders. In this case, the placeholders `{topic}` and `{number}` are defined in the template string. These placeholders can later be replaced with actual values using the `invoke()` method.\n",
    "\n",
    "The created `PromptTemplate` object allows for dynamic formatting of prompts by substituting the placeholders with specific values. This is particularly useful for generating customized prompts for language models.\n",
    "\n",
    "For example:\n",
    "- The template string `\"Please explain {topic} using exactly {number} detailed and distinct use cases.\"` is passed to `from_template()`.\n",
    "- The resulting `PromptTemplate` object can then be used to generate a formatted prompt by providing values for `topic` and `number`.\n",
    "\n",
    "This approach simplifies the process of creating reusable and parameterized prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Please explain langchain using exactly 2 detailed and distinct use cases.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Import the PromptTemplate class from langchain_core.prompts\n",
    "\n",
    "# Create a prompt template with placeholders for topic and number\n",
    "prompt_template = PromptTemplate.from_template(\"Please explain {topic} using exactly {number} detailed and distinct use cases.\")\n",
    "\n",
    "# Format the prompt by providing values for the placeholders\n",
    "formatted_prompt = prompt_template.invoke({\"topic\": \"langchain\", \"number\": 2})\n",
    "\n",
    "# Print the formatted prompt\n",
    "print(formatted_prompt)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a novel approach to natural language processing (NLP) that utilizes a combination of neural networks, attention mechanisms, and graph-based models to enable more efficient and effective text analysis. Here are two detailed and distinct use cases for LangChain:\n",
      "\n",
      "**Use Case 1: Sentiment Analysis of Social Media Posts**\n",
      "\n",
      "In this scenario, LangChain is used to analyze the sentiment of social media posts in real-time, enabling businesses to quickly identify and respond to customer feedback. The process works as follows:\n",
      "\n",
      "1. A user inputs a social media post containing text.\n",
      "2. The input is tokenized into individual words or phrases, which are then passed through a pre-trained neural network model (e.g., BERT) to extract relevant sentiment features (e.g., positive/negative sentiment).\n",
      "3. The extracted features are then combined with graph-based models (e.g., attention mechanisms) to identify the most relevant context-dependent features.\n",
      "4. These features are then used to predict the overall sentiment of the post, which is output as a probability distribution over all possible sentiments (e.g., positive, negative, neutral).\n",
      "5. The predicted sentiment can be used to inform business decisions, such as adjusting customer support responses or optimizing product pricing.\n",
      "\n",
      "**Use Case 2: Text Classification and Recommendation Systems**\n",
      "\n",
      "In this scenario, LangChain is used to classify text into predefined categories (e.g., spam vs. non-spam emails) and recommend relevant content based on user behavior. The process works as follows:\n",
      "\n",
      "1. A user submits a piece of text for classification.\n",
      "2. The input is tokenized into individual words or phrases, which are then passed through a pre-trained neural network model (e.g., transformer) to extract relevant features.\n",
      "3. The extracted features are then combined with graph-based models (e.g., attention mechanisms) to identify the most relevant context-dependent features.\n",
      "4. These features are used to train a classification model on a labeled dataset, which can be used to predict the category of the input text.\n",
      "5. Based on the predicted label, the system recommends relevant content from a knowledge graph or database, such as product recommendations for an e-commerce website.\n",
      "\n",
      "In both use cases, LangChain's unique combination of neural networks and graph-based models enables more accurate and efficient text analysis than traditional NLP methods. The ability to extract context-dependent features and combine them with graph-based models allows LangChain to capture nuanced relationships between words and phrases, which is critical for tasks like sentiment analysis and recommendation systems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Invoke the model with the formatted prompt\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source, cloud-native, graph-based conversational AI platform that enables developers to build, deploy, and manage conversational interfaces for various applications. Here are two detailed and distinct use cases of LangChain:\n",
      "\n",
      "**Use Case 1: Conversational Chatbots**\n",
      "\n",
      "LangChain can be used to build conversational chatbots that provide customers with personalized support and information about products or services. These chatbots can be integrated into websites, mobile apps, or messaging platforms to offer a seamless user experience.\n",
      "\n",
      "For example, an e-commerce company wants to create a conversational chatbot that can assist customers with product inquiries, order tracking, and returns. LangChain's graph-based architecture allows the developer to define intents (e.g., \"I want to know more about this product\"), entities (e.g., \"product name,\" \"price\"), and actions (e.g., \"provide a discount code\"). The chatbot can then use these definitions to generate responses based on user input, such as \"What is the price of this product?\" or \"Can you provide a refund for this order?\"\n",
      "\n",
      "LangChain's features include:\n",
      "\n",
      "* Intent recognition: Detects user intent and converts it into a recognizable format\n",
      "* Entity linking: Maps entities (e.g., product name) to their corresponding meanings\n",
      "* Action generation: Generates responses based on the detected intent, entities, and actions\n",
      "\n",
      "**Use Case 2: Customer Service Platforms for Complex Issues**\n",
      "\n",
      "LangChain can be used to build complex customer service platforms that handle high-volume issues, such as refunds, exchanges, or returns. These platforms require a deep understanding of customer behavior, product knowledge, and process rules.\n",
      "\n",
      "For instance, an airline wants to create a platform that handles complex customer complaints, such as lost luggage or flight delays. LangChain's graph-based architecture enables the development of a conversational interface that can:\n",
      "\n",
      "* Recognize customer intents (e.g., \"I'm experiencing a delay,\" \"My luggage has been lost\")\n",
      "* Map customer intent to specific process rules (e.g., \"Check with our customer service team for assistance with flight delays\")\n",
      "* Generate responses based on customer input and process rules, such as \"We're working on resolving your issue. Please wait 24 hours before contacting us again\"\n",
      "\n",
      "LangChain's features include:\n",
      "\n",
      "* Intent recognition: Detects customer intent and converts it into a recognizable format\n",
      "* Process rule mapping: Maps intents to specific process rules and actions (e.g., escalate to customer service team)\n",
      "* Response generation: Generates responses based on detected intent, entities, and\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, you can use the prompt_template as a chain using LCEL\n",
    "\n",
    "# Create chain\n",
    "chain = (\n",
    "     prompt_template\n",
    "    | llm\n",
    ")\n",
    "# Invoke the chain\n",
    "response = chain.invoke({\"topic\": \"langchain\", \"number\": 2})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2. Creating a PromptTemplate Object with Explicit Input Variables\n",
    "The code creates a `PromptTemplate` object and a prompt simultaneously by directly defining the template string and input variables in the constructor of the `PromptTemplate` class. Unlike the `from_template()` method, which is a convenience method for creating a `PromptTemplate` object from a single template string, this approach provides more flexibility by allowing you to explicitly specify the `input_variables` and other parameters during initialization.\n",
    "\n",
    "This method is particularly useful when you want to define additional attributes or customize the behavior of the `PromptTemplate` object beyond what the `from_template()` method offers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['number', 'topic'], input_types={}, partial_variables={}, template='Please explain {topic} using exactly {number} detailed and distinct use cases.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define template\n",
    "template = \"Please explain {topic} using exactly {number} detailed and distinct use cases.\"\n",
    "\n",
    "# Create a prompt template with `PromptTemplate` object\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"topic\", \"number\"],\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Please explain langchain using exactly 2 detailed and distinct use cases.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create prompt\n",
    "# Format the prompt by providing values for the placeholders\n",
    "formatted_prompt = prompt.invoke({\"topic\": \"langchain\", \"number\": 2})\n",
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a powerful, open-source, and highly customizable chatbot platform that allows developers to build conversational interfaces for various applications, including messaging apps, websites, and even internal business processes. Here are two detailed and distinct use cases of LangChain:\n",
      "\n",
      "**Use Case 1: Conversational Customer Support**\n",
      "\n",
      "In this scenario, a company like Amazon or Microsoft uses LangChain as the underlying technology to power its customer support chatbots. These chatbots can be triggered by user queries on the company's website or mobile app, and they respond with pre-defined responses based on a set of rules and intents defined in the LangChain platform.\n",
      "\n",
      "For example, when a user submits an inquiry about a product, the chatbot may detect the intent to ask for information and respond accordingly. If the user asks \"What is the weight of this product?\", the chatbot can retrieve relevant data from its knowledge base and provide a response like \"The weight of this product is 2 pounds.\" The chatbot then shares this information with the user, who can then proceed with their inquiry.\n",
      "\n",
      "LangChain's conversational capabilities allow for flexible and scalable support systems that can be easily integrated into existing customer service workflows. This enables companies to improve customer satisfaction, reduce support queries, and enhance their overall customer experience.\n",
      "\n",
      "**Use Case 2: Internal Knowledge Graph-Based Process Automation**\n",
      "\n",
      "In this scenario, a large enterprise like IBM or Accenture uses LangChain as the primary technology for building internal knowledge graphs that automate business processes and decision-making workflows. These knowledge graphs are based on a graph database that represents entities, relationships, and rules defined in the LangChain platform.\n",
      "\n",
      "For example, an HR department might create a knowledge graph to track employee information, including their job titles, departments, and performance metrics. The graph can be populated with data from various sources, such as databases, APIs, or even external data sources like social media platforms.\n",
      "\n",
      "When a new employee is hired, the LangChain-powered knowledge graph can automatically update the relevant information, ensuring that all stakeholders have access to accurate and up-to-date data. This enables faster decision-making, reduced errors, and improved overall business efficiency.\n",
      "\n",
      "LangChain's ability to handle complex relationships between entities and rules allows for efficient and scalable automation of internal processes, making it an attractive solution for large enterprises looking to optimize their workflows and improve their bottom line.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the model with the formatted prompt\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source, multi-language neural network model developed by Meta AI that enables the integration of multiple programming languages into a single, unified platform. Here are two detailed and distinct use cases for LangChain:\n",
      "\n",
      "**Use Case 1: Natural Language Processing (NLP) with Multiple Languages**\n",
      "\n",
      "In this scenario, LangChain is used to develop a conversational AI system that can understand and generate text in multiple languages simultaneously. For example, a customer service chatbot built using LangChain might be able to engage with customers who speak different languages, such as English, Spanish, French, or Mandarin Chinese.\n",
      "\n",
      "To achieve this, the LangChain model would be trained on a dataset of texts from various sources, including books, articles, and websites in each supported language. This training data would allow the model to learn patterns and relationships between words and phrases across multiple languages.\n",
      "\n",
      "Once trained, the LangChain model can be used to generate responses to customer inquiries or questions in different languages. For instance, if a user asks \"How do I return an item?\" in English, the chatbot might respond with \"To return an item, please contact our customer service team in your language of preference.\" This approach enables the system to provide accurate and culturally sensitive information to customers across multiple languages.\n",
      "\n",
      "**Use Case 2: Data Integration and Knowledge Graphs**\n",
      "\n",
      "In this scenario, LangChain is used as a key component in building a knowledge graph that integrates data from multiple sources into a single, unified platform. For example, a company might use LangChain to integrate data from various sources, such as customer feedback, product reviews, and social media posts, into a single knowledge graph.\n",
      "\n",
      "The LangChain model would be trained on the integrated data, allowing it to learn patterns and relationships between different pieces of information across multiple domains. This training data would enable the model to generate insights and answers that can be used to inform business decisions or improve customer experiences.\n",
      "\n",
      "For instance, if a company wants to analyze customer reviews for their products, LangChain could be used to integrate data from various sources, such as Amazon reviews, social media posts, and product feedback forms. The trained model would then be able to generate insights on customer satisfaction, product quality, and other relevant metrics, enabling the company to make data-driven decisions that improve their products and services.\n",
      "\n",
      "In both use cases, LangChain's ability to integrate multiple languages and knowledge domains enables seamless communication and information exchange between different sources, ultimately improving the accuracy and effectiveness of the system.\n"
     ]
    }
   ],
   "source": [
    " # Alternatively, you can use the prompt_template as a chain using LCEL\n",
    "chain = (\n",
    "    prompt\n",
    "    | llm\n",
    ")\n",
    "# Invoke the chain\n",
    "response = chain.invoke({\"topic\": \"langchain\", \"number\": 2})\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
