{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatPromptTemplate\n",
    "ChatPromptTemplate is a powerful tool in LangChain that allows you to define structured prompts for conversational AI models. It enables you to create prompts with multiple message types and provides flexibility for complex conversational scenarios.\n",
    "\n",
    "Key characteristics of ChatPromptTemplate:\n",
    "\n",
    "- Supports multiple message types (system, human, AI)\n",
    "- Can include context and role-specific instructions\n",
    "- More flexible for complex conversational scenarios\n",
    "- Outputs a list of messages\n",
    "- Better suited for chat models that expect a sequence of messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Aspect               | PromptTemplate                          | ChatPromptTemplate                          |\n",
    "|-----------------------|-----------------------------------------|---------------------------------------------|\n",
    "| **Message Structure** | Single string                          | Multiple message types (system, human, AI) |\n",
    "| **Use Cases**         | Simple, single-turn interactions       | Multi-turn conversations, context-rich interactions |\n",
    "| **Model Compatibility** | Works with traditional language models | Designed for chat-based models             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### When to Use Each\n",
    "\n",
    "**Use `PromptTemplate` for:**\n",
    "- Simple, single-turn queries\n",
    "- Traditional language models\n",
    "- Straightforward text generation\n",
    "\n",
    "**Use `ChatPromptTemplate` for:**\n",
    "- Conversational AI\n",
    "- Multi-turn interactions\n",
    "- Scenarios requiring context or role-based instructions\n",
    "- Chat models like GPT-3.5, GPT-4\n",
    "\n",
    "The choice depends on your specific use case and the type of language model you're using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model=model,\n",
    "    temperature=0.5,\n",
    "    num_predict=512\n",
    "    #timeout=None,\n",
    "    # max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['number', 'topic'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assistant specialized in explaining technical concepts.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['number', 'topic'], input_types={}, partial_variables={}, template='Please explain {topic} using exactly {number} detailed and distinct use cases.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a ChatPromptTemplate with multiple message types\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant specialized in explaining technical concepts.\"),\n",
    "    (\"human\", \"Please explain {topic} using exactly {number} detailed and distinct use cases.\")\n",
    "])\n",
    "\n",
    "# Invoke the chat prompt with specific values\n",
    "formatted_chat_prompt = chat_prompt.invoke({\n",
    "    \"topic\": \"langchain\", \n",
    "    \"number\": 5\n",
    "})\n",
    "chat_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI assistant specialized in explaining technical concepts.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Please explain langchain using exactly 5 detailed and distinct use cases.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source, web-based conversational AI platform that enables developers to build and deploy conversational interfaces using a simple and intuitive API. Here are five detailed and distinct use cases for LangChain:\n",
      "\n",
      "**Use Case 1: Conversational Chatbots**\n",
      "\n",
      "LangChain can be used to build conversational chatbots that provide customer support, answer frequently asked questions, or engage in basic conversations with users. Developers can create a chatbot by defining a set of intents (user actions) and corresponding responses, which are then executed using LangChain's API.\n",
      "\n",
      "For example, a customer service chatbot might be built to respond to common issues such as \"I want to return an item,\" \"I need help with my order,\" or \"What is the shipping policy.\" The chatbot would use LangChain's API to retrieve user input, determine the intent, and generate a response based on predefined rules.\n",
      "\n",
      "**Use Case 2: Virtual Assistants**\n",
      "\n",
      "LangChain can be used to build virtual assistants that provide users with information, schedules, or reminders. Developers can create a virtual assistant by defining a set of intents (user actions) and corresponding responses, which are then executed using LangChain's API.\n",
      "\n",
      "For example, a virtual assistant might be built to schedule appointments, remind users about upcoming events, or provide weather forecasts. The virtual assistant would use LangChain's API to retrieve user input, determine the intent, and generate a response based on predefined rules.\n",
      "\n",
      "**Use Case 3: Language Translation Platforms**\n",
      "\n",
      "LangChain can be used to build language translation platforms that enable real-time translations between languages. Developers can create a translation platform by defining a set of intents (user actions) and corresponding responses, which are then executed using LangChain's API.\n",
      "\n",
      "For example, a language translation platform might be built to translate text from English to Spanish or French, with the ability to detect grammar and syntax errors. The platform would use LangChain's API to retrieve user input, determine the intent, and generate a translated response based on predefined rules.\n",
      "\n",
      "**Use Case 4: Sentiment Analysis and Opinion Mining**\n",
      "\n",
      "LangChain can be used to build sentiment analysis and opinion mining tools that analyze user feedback and opinions. Developers can create a sentiment analysis tool by defining a set of intents (user actions) and corresponding responses, which are then executed using LangChain's API.\n",
      "\n",
      "For example, a sentiment analysis tool might be built to analyze customer reviews, detect positive or negative sentiments, and provide recommendations for improvement. The tool would use LangChain's API to retrieve user input, determine\n"
     ]
    }
   ],
   "source": [
    "# Invoke the model with the formatted prompt\n",
    "response = llm.invoke(formatted_chat_prompt)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI assistant who explains technical concepts in a friendly, approachable manner.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you help me understand what langchain is?', additional_kwargs={}, response_metadata={}), AIMessage(content='langchain is a powerful framework for developing applications powered by large language models. It provides tools to help chain together different components of AI applications.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Please explain langchain using exactly 5 detailed and distinct use cases.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same example as above but with conversational context\n",
    "\n",
    "# Create a ChatPromptTemplate that simulates a more interactive conversation\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # Role , Message\n",
    "    # System message sets the overall context and behavior\n",
    "    (\"system\", \"You are a helpful AI assistant who explains technical concepts in a friendly, approachable manner.\"),\n",
    "    \n",
    "    # First human message sets up the initial context\n",
    "    (\"human\", \"Can you help me understand what {topic} is?\"),\n",
    "    \n",
    "    # An example AI response (this helps provide context for the model)\n",
    "    (\"ai\", \"{topic} is a powerful framework for developing applications powered by large language models. It provides tools to help chain together different components of AI applications.\"),\n",
    "    \n",
    "    # Another human follow-up message\n",
    "    (\"human\", \"Please explain {topic} using exactly {number} detailed and distinct use cases.\")\n",
    "])\n",
    "\n",
    "# Invoke the prompt with specific values\n",
    "formatted_chat_prompt = chat_prompt.invoke({\n",
    "    \"number\": 5,\n",
    "    \"topic\": \"langchain\"\n",
    "})\n",
    "\n",
    "formatted_chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are five detailed and distinct use cases that illustrate the capabilities of langchain:\\n\\n**Use Case 1: Text Summarization**\\n\\nLangchain can be used to build a text summarization model that takes in a large piece of text, such as an article or blog post, and outputs a concise summary. This is achieved by chaining together multiple components, including a tokenizer, a language model (e.g., BERT), a summarizer (e.g., RoBERTa), and a sentiment analyzer.\\n\\n* Tokenization: The input text is broken down into individual words or tokens.\\n* Language Modeling: A pre-trained language model (e.g., BERT) is used to generate context for each token, allowing the model to understand the relationships between words.\\n* Summarization: The summarizer component is chained with the language model to produce a summary of the input text. This process involves selecting relevant keywords and phrases from the original text, while also considering the context and relationships between words.\\n* Sentiment Analysis: To provide an additional layer of nuance, sentiment analysis can be used to determine the emotional tone of the summarized text.\\n\\n**Use Case 2: Chatbots for Customer Support**\\n\\nLangchain can be employed to build a chatbot that uses natural language processing (NLP) and machine learning algorithms to understand customer inquiries. The chatbot can then respond with relevant information or solutions, while also incorporating additional components such as sentiment analysis and entity recognition.\\n\\n* NLP: A pre-trained language model is used to analyze the input customer query and identify key entities, such as names, dates, and locations.\\n* Sentiment Analysis: The chatbot's response is evaluated using sentiment analysis to determine whether it is friendly, informative, or entertaining.\\n* Entity Recognition: To provide more accurate responses, entity recognition can be used to extract specific information from the input query, such as customer names or product details.\\n\\n**Use Case 3: Content Generation**\\n\\nLangchain can be utilized to create content for various purposes, including blog posts, social media updates, and even entire websites. By chaining together multiple components, such as text generation models (e.g., transformer-based architectures), style transfer, and image generation, it is possible to produce high-quality content that is tailored to specific audiences.\\n\\n* Text Generation: A pre-trained language model is used to generate the main content of the article or social media post.\\n* Style Transfer: The generated content is then transformed using style transfer techniques to make it more visually appealing or engaging.\\n* Image Generation: To add an\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(formatted_chat_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langchain is an open-source, cloud-native platform that enables the development of scalable and fault-tolerant AI applications by providing a flexible framework for chaining together multiple models, data sources, and processing pipelines. Here are five detailed and distinct use cases to illustrate the capabilities of langchain:\\n\\n**Use Case 1: Text Summarization**\\n\\nSuppose you want to build an AI-powered news aggregator that summarizes long articles into concise bullet points. Langchain can help by chaining together a text summarization model (e.g., BART or T5) with a data source for article content (e.g., a database of news articles). The model would be trained on a large corpus of text, and the data source would provide access to relevant articles. Once the summary is generated, the pipeline can output the summarized text as a bullet point.\\n\\n**Use Case 2: Sentiment Analysis with Multiple Models**\\n\\nImagine you want to develop an AI-powered customer service chatbot that can analyze customer feedback and sentiment using multiple models (e.g., NLTK, spaCy, or Stanford CoreNLP). Langchain allows you to chain together these models in a pipeline, where each model would provide its own insights into the customer's sentiment. The final output could be a unified sentiment analysis report that incorporates the outputs from all participating models.\\n\\n**Use Case 3: Data Preprocessing for Machine Learning**\\n\\nSuppose you're building an AI model for predictive analytics and need to preprocess large datasets (e.g., CSV files or JSON objects) before feeding them into the model. Langchain can help by chaining together data processing pipelines, such as data cleaning, feature extraction, and dimensionality reduction. Each pipeline would be composed of multiple models (e.g., PCA, Lasso regression, or word embeddings), which would work together to ensure the quality and relevance of the preprocessed data.\\n\\n**Use Case 4: Conversational AI with Multiple Dialogue Models**\\n\\nPicture a chatbot that can engage in conversations with users using multiple dialogue models (e.g., transformer-based models like BERT or RoBERTa). Langchain enables you to chain together these models, where each model would generate responses based on the context and input from the previous model. The final output could be a coherent and natural-sounding conversation that incorporates insights from all participating models.\\n\\n**Use Case 5: Recommendation Systems with Multiple Model Chains**\\n\\nSuppose you want to build an AI-powered e-commerce recommendation system that suggests products based on user behavior and preferences. Langchain allows you to chain together multiple model chains,\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, you can use the `invoke` method directly on the ChatPromptTemplate using LCEL\n",
    "chain = chat_prompt | llm\n",
    "chain.invoke({ \"number\": 5,\n",
    "    \"topic\": \"langchain\"}).content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
